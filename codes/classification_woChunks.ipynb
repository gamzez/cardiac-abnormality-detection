{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Training - Without chunks\n",
    "This script is creating the complete dataset and training various classifiers. \n",
    "\n",
    "The processing is as follows:\n",
    "1. PCG records are loaded.\n",
    "2. Records are normalized usng RMS normalization\n",
    "3. Extraction of feature 1: **PCA of MFCC**\n",
    "4. Extraction of feature 2: **Statistics of MFCC**\n",
    "5. Extraction of feature 3: **Bandpower ratio**\n",
    "6. Loading segmentation features and mergin all features and labels into a single array\n",
    "7. Calculating K-Fold validation for Logistic Regression, Random Forest and AdaBoost classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import scipy\n",
    "from utils import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading and RMS Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_records, normal_records_denoised = load_records(path = '../dataset/normal_tracings.txt',normalize = False, crop = 20000)\n",
    "abnormal_records, abnormal_records_denoised = load_records(path = '../dataset/abnormal_tracings.txt',normalize = False, crop = 20000)\n",
    "all_records = np.concatenate((abnormal_records_denoised, normal_records_denoised), axis=0)\n",
    "labels = np.concatenate((np.ones((abnormal_records_denoised.shape[0],1)),np.zeros((normal_records.shape[0],1))), axis=0)\n",
    "all_records_normalized = np.zeros_like(all_records)\n",
    "\n",
    "## RMS normalization\n",
    "for i in range(all_records.shape[0]):\n",
    "    data = all_records[i,:]\n",
    "    rms_level = 0\n",
    "    r = 10**(rms_level / 10.0)\n",
    "    a = np.sqrt( (len(data) * r**2) / np.sum(data**2) )\n",
    "    data = data * a\n",
    "    all_records_normalized[i,:] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 1: PCA of MFCC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mfcc = []\n",
    "all_mfcc_delta = []\n",
    "all_mfcc_delta2 = []\n",
    "for im in range(all_records_normalized.shape[0]): \n",
    "    mfc_coefs = mfcc(all_records_normalized[im,:],  samplerate=2000, winlen =0.1, winstep = 0.1, nfft = 1024)\n",
    "    mfc_coefs = mfc_coefs.T\n",
    "    delta_mfc_coefs = delta(mfc_coefs, 3)\n",
    "    delta2_mfc_coefs = delta(delta_mfc_coefs, 2)\n",
    "    \n",
    "    all_mfcc.append(mfc_coefs)\n",
    "    all_mfcc_delta.append(delta_mfc_coefs)\n",
    "    all_mfcc_delta2.append(delta2_mfc_coefs)\n",
    "\n",
    "all_mfcc = np.array(all_mfcc)\n",
    "all_mfcc_delta = np.array(all_mfcc_delta)\n",
    "all_mfcc_delta2 = np.array(all_mfcc_delta2)\n",
    "\n",
    "mfcc_pca = []\n",
    "for im in range(0,13):\n",
    "    pca = PCA(n_components=1)\n",
    "    mfcc_transformed = pca.fit_transform(np.array(all_mfcc)[:,im,:])\n",
    "    mfcc_pca.append(mfcc_transformed[:,0])  \n",
    "mfcc_pca = np.array(mfcc_pca).T  #248x13\n",
    "\n",
    "delta_mfcc_pca = []\n",
    "for im in range(0,13):\n",
    "    pca = PCA(n_components=1)\n",
    "    delta_mfcc_transformed = pca.fit_transform(np.array(all_mfcc_delta)[:,im,:])\n",
    "    delta_mfcc_pca.append(delta_mfcc_transformed[:,0])\n",
    "delta_mfcc_pca = np.array(delta_mfcc_pca).T  #248x13\n",
    "\n",
    "delta2_mfcc_pca = []\n",
    "for im in range(0,13):\n",
    "    pca = PCA(n_components=1)\n",
    "    delta2_mfcc_transformed = pca.fit_transform(np.array(all_mfcc_delta2)[:,im,:])\n",
    "    delta2_mfcc_pca.append(delta2_mfcc_transformed[:,0])\n",
    "delta2_mfcc_pca = np.array(delta2_mfcc_pca).T  #248x13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 2: Statistics of MFCC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_means = np.zeros((all_records_normalized.shape[0],13),dtype='float32')  \n",
    "mfcc_std = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "mfcc_max = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "mfcc_min = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "\n",
    "mfcc_delta_means = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "mfcc_delta_std = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "mfcc_delta_max = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "mfcc_delta_min = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "\n",
    "mfcc_delta2_means = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "mfcc_delta2_std = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "mfcc_delta2_max = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "mfcc_delta2_min = np.zeros((all_records_normalized.shape[0],13),dtype='float32')\n",
    "\n",
    "\n",
    "for im in range(all_records_normalized.shape[0]):   \n",
    "    for j in range(13):\n",
    "        mfcc_means[im,j] = np.mean(all_mfcc[im,j,:])\n",
    "        mfcc_std[im,j] = np.std(all_mfcc[im,j,:])\n",
    "        mfcc_max[im,j] = np.max(all_mfcc[im,j,:])\n",
    "        mfcc_min[im,j] = np.min(all_mfcc[im,j,:])\n",
    "        \n",
    "        mfcc_delta_means[im,j] = np.mean(all_mfcc_delta[im,j,:])\n",
    "        mfcc_delta_std[im,j] = np.std(all_mfcc_delta[im,j,:])\n",
    "        mfcc_delta_max[im,j] = np.max(all_mfcc_delta[im,j,:])\n",
    "        mfcc_delta_min[im,j] = np.min(all_mfcc_delta[im,j,:])\n",
    "        \n",
    "        mfcc_delta2_means[im,j] = np.mean(all_mfcc_delta2[im,j,:])\n",
    "        mfcc_delta2_std[im,j] = np.std(all_mfcc_delta2[im,j,:])\n",
    "        mfcc_delta2_max[im,j] = np.max(all_mfcc_delta2[im,j,:])\n",
    "        mfcc_delta2_min[im,j] = np.min(all_mfcc_delta2[im,j,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 3: Bandpower ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_start = 35\n",
    "bin_end = 70\n",
    "all_bandpowers = np.zeros((all_records_normalized.shape[0],1))   \n",
    "for i in range(0,all_records_normalized.shape[0]):  ###number of abnormal recs\n",
    "    total_power = bandpower(all_records_normalized[i,:],2000,0,1000)\n",
    "    bp = bandpower(all_records_normalized[i,:],2000,bin_start,bin_end)\n",
    "    #print(bp)\n",
    "    all_bandpowers[i,0] = 10*np.log10(bp/total_power)\n",
    "bandpower_feature = all_bandpowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all features  (60, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berka\\AppData\\Local\\Temp/ipykernel_24052/3710436307.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ratio = all_mean_S1[0::4] / all_mean_S2[2::4]\n"
     ]
    }
   ],
   "source": [
    "pca_feature_1 = np.expand_dims(mfcc_pca[:,6], axis=-1)\n",
    "pca_feature_2 = np.expand_dims(mfcc_pca[:,7], axis=-1)\n",
    "\n",
    "sts_feature_1 = np.expand_dims(mfcc_min[:,7], axis=-1) \n",
    "sts_feature_2 = np.expand_dims(mfcc_min[:,8], axis=-1) \n",
    "\n",
    "all_mean_S1 = np.load(\"cardiac_cycle_segmentation_features/all_mean_S1.npy\")\n",
    "all_mean_S2 = np.load(\"cardiac_cycle_segmentation_features/all_mean_S2.npy\")\n",
    "all_std_S1 = np.load(\"cardiac_cycle_segmentation_features/all_std_S1.npy\")\n",
    "all_std_S2 = np.load(\"cardiac_cycle_segmentation_features/all_std_S2.npy\")\n",
    "all_mean_S1_woChunk = all_mean_S1[0::4]\n",
    "all_mean_S2_woChunk = all_mean_S2[2::4]\n",
    "all_std_S1_woChunk = all_std_S1[0::4]\n",
    "all_std_S2_woChunk = all_std_S2[1::4]\n",
    "ratio = all_mean_S1[0::4] / all_mean_S2[2::4]\n",
    "\n",
    "all_features = np.concatenate((pca_feature_1, pca_feature_2, sts_feature_1, sts_feature_2, bandpower_feature, ratio, all_std_S1_woChunk, all_std_S2_woChunk, all_mean_S1_woChunk, all_mean_S2_woChunk), axis = -1)\n",
    "\n",
    "rejection = [17,27]  \n",
    "all_features_woRejections = np.delete(all_features, rejection, axis = 0)\n",
    "labels_chunked_woRejections = np.delete(labels, rejection, axis = 0)\n",
    "print(f'Shape of all features  {all_features_woRejections.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean LR train set accuracy is 0.8291666666666666%\n",
      "mean LR test set accuracy is 0.7000000000000001%\n",
      "mean RF train set accuracy is 1.0%\n",
      "mean RF test set accuracy is 0.7333333333333334%\n",
      "mean AB train set accuracy is 1.0%\n",
      "mean AB test set accuracy is 0.7333333333333333%\n"
     ]
    }
   ],
   "source": [
    "num_fold = 5\n",
    "chunk_number = 1\n",
    "num_records = 60\n",
    "fold_length = int(num_records/num_fold)\n",
    "\n",
    "abnormal_feature_matrix = np.array(all_features_woRejections[0:31,:]) #(124, 15)\n",
    "normal_feature_matrix = np.array(all_features_woRejections[31:60,:]) #(116, 15)\n",
    "labels_abnormal_features = np.array(labels_chunked_woRejections[0:31,:]) #(124, 15)\n",
    "labels_normal_features = np.array(labels_chunked_woRejections[31:60,:]) #(124, 15)\n",
    "\n",
    "### Shuffling\n",
    "indices_abnormal = np.arange(0,31,1) \n",
    "np.random.shuffle(indices_abnormal)\n",
    "indices_abnormal = indices_abnormal.astype(int)\n",
    "indices_normal = np.arange(0,29,1) \n",
    "np.random.shuffle(indices_normal)\n",
    "indices_normal = indices_normal.astype(int)\n",
    "\n",
    "abnormal_feature_matrix = np.reshape(abnormal_feature_matrix, (31,10))\n",
    "labels_abnormal_features = np.reshape(labels_abnormal_features, (31,1)) \n",
    "normal_feature_matrix = np.reshape(normal_feature_matrix, (29,10))\n",
    "labels_normal_features = np.reshape(labels_normal_features, (29,1)) \n",
    "\n",
    "abnormal_features_shuffled = np.array((abnormal_feature_matrix)[indices_abnormal])\n",
    "normal_features_shuffled = np.array((normal_feature_matrix)[indices_normal])\n",
    "\n",
    "labels_abnormal_shuffled = np.array((labels_abnormal_features)[indices_abnormal])\n",
    "labels_normal_shuffled = np.array((labels_normal_features)[indices_normal])\n",
    "\n",
    "feature_matrix=np.zeros((58,10)) \n",
    "label_matrix=np.zeros((58,1)) \n",
    "\n",
    "for k in range (0,29):\n",
    "    n = random.randint(0,1)\n",
    "    if n==0:\n",
    "        feature_matrix[2*k,:] = abnormal_features_shuffled[k,:] \n",
    "        label_matrix[2*k,:] = labels_abnormal_shuffled[k,:]\n",
    "        feature_matrix[2*k+1,:] = normal_features_shuffled[k,:]\n",
    "        label_matrix[2*k+1,:] = labels_normal_shuffled[k,:]\n",
    "    else:\n",
    "        feature_matrix[2*k,:] = normal_features_shuffled[k,:] \n",
    "        label_matrix[2*k,:] = labels_normal_shuffled[k,:]\n",
    "        feature_matrix[2*k+1,:] = abnormal_features_shuffled[k,:]\n",
    "        label_matrix[2*k+1,:] = labels_abnormal_shuffled[k,:]\n",
    "     \n",
    "\n",
    "a = random.randint(0,58)\n",
    "feature_matrix = np.insert(feature_matrix,a,abnormal_features_shuffled[29,:],axis=0)\n",
    "label_matrix = np.insert(label_matrix,a,labels_abnormal_shuffled[29,:],axis=0)\n",
    "\n",
    "a = random.randint(0,59)\n",
    "feature_matrix = np.insert(feature_matrix,a,abnormal_features_shuffled[30,:],axis=0)\n",
    "label_matrix = np.insert(label_matrix,a,labels_abnormal_shuffled[30,:],axis=0)\n",
    "\n",
    "feature_matrix = np.reshape(feature_matrix,(60,10))\n",
    "label_matrix = np.reshape(label_matrix, (60,1))\n",
    "\n",
    "LR_train_accuracy = []\n",
    "LR_test_accuracy = []\n",
    "RF_train_accuracy = []\n",
    "RF_test_accuracy = []\n",
    "AB_train_accuracy = []\n",
    "AB_test_accuracy = []\n",
    "\n",
    "for i in range(num_fold):\n",
    "    test_selection = np.arange(fold_length * i, fold_length * (i+1))  \n",
    "    X_train = np.delete(feature_matrix, test_selection, axis = 0) \n",
    "    X_test = feature_matrix[test_selection,:]\n",
    "    y_train = np.ravel(np.delete(label_matrix, test_selection, axis = 0))\n",
    "    y_test = np.ravel(label_matrix[test_selection])\n",
    "    RF = RandomForestClassifier(max_depth=25,  n_estimators = 150)\n",
    "    RF.fit(X_train, y_train)\n",
    "    LR = LogisticRegression(max_iter=4000)\n",
    "    LR.fit(X_train, y_train)\n",
    "    AB = AdaBoostClassifier(n_estimators = 50)\n",
    "    AB.fit(X_train, y_train)\n",
    "    LR_train_accuracy.append(LR.score(X_train, y_train))\n",
    "    LR_test_accuracy.append(LR.score(X_test, y_test))\n",
    "    RF_train_accuracy.append(RF.score(X_train, y_train))\n",
    "    RF_test_accuracy.append(RF.score(X_test, y_test))\n",
    "    AB_train_accuracy.append(AB.score(X_train, y_train))\n",
    "    AB_test_accuracy.append(AB.score(X_test, y_test))\n",
    "\n",
    "mean_LR_train_accuracy = np.mean(np.array(LR_train_accuracy))\n",
    "mean_LR_test_accuracy = np.mean(np.array(LR_test_accuracy))   \n",
    "mean_RF_train_accuracy = np.mean(np.array(RF_train_accuracy))\n",
    "mean_RF_test_accuracy = np.mean(np.array(RF_test_accuracy))\n",
    "mean_AB_train_accuracy = np.mean(np.array(AB_train_accuracy))\n",
    "mean_AB_test_accuracy = np.mean(np.array(AB_test_accuracy))\n",
    "\n",
    "print(f'mean LR train set accuracy is {mean_LR_train_accuracy}%')\n",
    "print(f'mean LR test set accuracy is {mean_LR_test_accuracy}%')\n",
    "print(f'mean RF train set accuracy is {mean_RF_train_accuracy}%')\n",
    "print(f'mean RF test set accuracy is {mean_RF_test_accuracy}%')\n",
    "print(f'mean AB train set accuracy is {mean_AB_train_accuracy}%')\n",
    "print(f'mean AB test set accuracy is {mean_AB_test_accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c1921d6cb1bbb6d983fc9ed48edae35d2edb378643e089b074f8a35a8a8a2d1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gamze_thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
